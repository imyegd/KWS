{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "\n",
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "def which_set(filename, validation_percentage=10, testing_percentage=10):\n",
    "  \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "  We want to keep files in the same training, validation, or testing sets even\n",
    "  if new ones are added over time. This makes it less likely that testing\n",
    "  samples will accidentally be reused in training when long runs are restarted\n",
    "  for example. To keep this stability, a hash of the filename is taken and used\n",
    "  to determine which set it should belong to. This determination only depends on\n",
    "  the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "  It's also useful to associate particular files as related (for example words\n",
    "  spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "  ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "  'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "  Args:\n",
    "    filename: File path of the data sample.\n",
    "    validation_percentage: How much of the data set to use for validation.\n",
    "    testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "  Returns:\n",
    "    String, one of 'training', 'validation', or 'testing'.\n",
    "  \"\"\"\n",
    "  base_name = os.path.basename(filename)\n",
    "  # We want to ignore anything after '_nohash_' in the file name when\n",
    "  # deciding which set to put a wav in, so the data set creator has a way of\n",
    "  # grouping wavs that are close variations of each other.\n",
    "  hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "  # This looks a bit magical, but we need to decide whether this file should\n",
    "  # go into the training, testing, or validation sets, and we want to keep\n",
    "  # existing files in the same set even if more files are subsequently\n",
    "  # added.\n",
    "  # To do that, we need a stable way of deciding based on just the file name\n",
    "  # itself, so we do a hash of that and then use that to generate a\n",
    "  # probability value that we use to assign it.\n",
    "  hash_name_encoded = hash_name.encode('utf-8')\n",
    "  hash_name_hashed = hashlib.sha1(hash_name_encoded).hexdigest()\n",
    "  percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "  if percentage_hash < validation_percentage:\n",
    "    result = 'validation'\n",
    "  elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "    result = 'testing'\n",
    "  else:\n",
    "    result = 'training'\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_files(directory):\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if which_set(file) == 'validation':\n",
    "                item = os.path.join(root, file)\n",
    "                item = item[len(directory) + 1:]\n",
    "                val_list.append(item)\n",
    "            elif which_set(file) == 'testing':\n",
    "                item = os.path.join(root, file)\n",
    "                item = item[len(directory) + 1:]\n",
    "                test_list.append(item)\n",
    "    return val_list, test_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = './data/data_mini_merge'\n",
    "val_list, test_list = list_files(directory_path)\n",
    "output_path = './data'\n",
    "\n",
    "test_file = os.path.join(output_path, 'testing_list.txt')\n",
    "val_file = os.path.join(output_path, 'validating_list.txt')\n",
    "\n",
    "\n",
    "with open(val_file, 'w') as file:\n",
    "    for item in val_list:\n",
    "        # 写入列表中的每个元素，后面添加换行符\n",
    "        file.write(item + '\\n')\n",
    "\n",
    "with open(test_file, 'w') as file:\n",
    "    for item in test_list:\n",
    "        # 写入列表中的每个元素，后面添加换行符\n",
    "        file.write(item + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KWS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
